åŸæ–‡ï¼šhttps://docs.raku.org/language/unicode

# ä¸‡å›½ç  / Unicode

Raku ä¸­çš„ Unicode æ”¯æŒ

Unicode support in Raku

Raku é«˜åº¦æ”¯æŒ Unicodeã€‚æœ¬æ–‡æ¡£æ—¨åœ¨å¯¹ä¸å±äºä¾‹ç¨‹å’Œæ–¹æ³•çš„æ–‡æ¡£ä¸­çš„ Unicode ç‰¹æ€§è¿›è¡Œæ¦‚è¿°å’Œæè¿°ã€‚

Raku has a high level of support of Unicode. This document aims to be both an overview as well as description of Unicode features which don't belong in the documentation for routines and methods.

æœ‰å…³ MoarVM å†…éƒ¨å­—ç¬¦ä¸²è¡¨ç¤ºçš„æ¦‚è¿°ï¼Œè¯·å‚é˜… [MoarVM å­—ç¬¦ä¸²æ–‡æ¡£](https://github.com/MoarVM/MoarVM/blob/master/docs/strings.asciidoc)ã€‚

For an overview on MoarVM's internal representation of strings, see the [MoarVM string documentation](https://github.com/MoarVM/MoarVM/blob/master/docs/strings.asciidoc).

<!-- MarkdownTOC -->

- [æ–‡ä»¶å¥æŸ„å’Œ I/O Filehandles and I/O](#æ–‡ä»¶å¥æŸ„å’Œ-io-filehandles-and-io)
	- [è§„èŒƒåŒ– / Normalization](#è§„èŒƒåŒ–--normalization)
	- [UTF8-C8](#utf8-c8)
- [è¾“å…¥ Unicode ç ç‚¹å’Œç ç‚¹åºåˆ— / Entering unicode codepoints and codepoint sequences](#è¾“å…¥-unicode-ç ç‚¹å’Œç ç‚¹åºåˆ—--entering-unicode-codepoints-and-codepoint-sequences)
	- [åç§°åˆ«å / Name aliases](#åç§°åˆ«å--name-aliases)
	- [å‘½ååºåˆ— / Named sequences](#å‘½ååºåˆ—--named-sequences)
		- [è¡¨æƒ…åºåˆ— / Emoji sequences](#è¡¨æƒ…åºåˆ—--emoji-sequences)

<!-- /MarkdownTOC -->

<a id="æ–‡ä»¶å¥æŸ„å’Œ-io-filehandles-and-io"></a>
# æ–‡ä»¶å¥æŸ„å’Œ I/O Filehandles and I/O

<a id="è§„èŒƒåŒ–--normalization"></a>
## è§„èŒƒåŒ– / Normalization

Raku é»˜è®¤æƒ…å†µä¸‹å¯¹æ‰€æœ‰è¾“å…¥å’Œè¾“å‡ºåº”ç”¨è§„èŒƒåŒ–ï¼Œä½†æ–‡ä»¶åé™¤å¤–ï¼Œè¿™äº›æ–‡ä»¶åè¢«è¯»å’Œå†™ä¸º [`UTF8-C8`](https://docs.raku.org/language/unicode#UTF8-C8)ï¼›å­—ç´ ä½œä¸ºç”¨æˆ·å¯è§çš„å­—ç¬¦å½¢å¼çš„å›¾å½¢ç¬¦å·å°†ä½¿ç”¨è§„èŒƒåŒ–è¡¨ç¤ºå½¢å¼ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ç”¨ä¸¤ç§æ–¹å¼è¡¨ç¤ºå­—å½¢ç´  `Ã¡`ï¼Œè¦ä¹ˆä½¿ç”¨ä¸€ä¸ªç ç‚¹ï¼š

Raku applies normalization by default to all input and output except for file names, which are read and written as [`UTF8-C8`](https://docs.raku.org/language/unicode#UTF8-C8); graphemes, which are user-visible forms of the characters, will use a normalized representation. For example, the grapheme `Ã¡` can be represented in two ways, either using one codepoint:

```Raku
Ã¡ (U+E1 "LATIN SMALL LETTER A WITH ACUTE")
```

æˆ–äºŒä¸ªç ç‚¹ï¼š

Or two codepoints:

```Raku
a +  Ì (U+61 "LATIN SMALL LETTER A" + U+301 "COMBINING ACUTE ACCENT")
```

Raku å°†è¿™ä¸¤ä¸ªè¾“å…¥è½¬æ¢ä¸ºä¸€ä¸ªç ç‚¹ï¼Œè¿™æ˜¯ä¸ºè§„èŒƒåŒ–å½¢å¼ Cï¼ˆ*NFC*ï¼‰æŒ‡å®šçš„ã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œè¿™æ˜¯æœ‰ç”¨çš„ï¼Œè¿™æ„å‘³ç€ä¸¤ä¸ªç­‰ä»·çš„è¾“å…¥éƒ½æ˜¯ç›¸åŒçš„ã€‚Unicode æœ‰ä¸€ä¸ªè§„èŒƒç­‰ä»·çš„æ¦‚å¿µï¼Œå®ƒå…è®¸æˆ‘ä»¬ç¡®å®šå­—ç¬¦ä¸²çš„è§„èŒƒå½¢å¼ï¼Œå…è®¸æˆ‘ä»¬æ­£ç¡®åœ°æ¯”è¾ƒå’Œæ“ä½œå­—ç¬¦ä¸²ï¼Œè€Œä¸å¿…æ‹…å¿ƒæ–‡æœ¬ä¼šä¸¢å¤±è¿™äº›å±æ€§ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œä½ ä» Raku å¤„ç†æˆ–è¾“å‡ºçš„ä»»ä½•æ–‡æœ¬éƒ½å°†ä»¥â€œè§„èŒƒâ€å½¢å¼å‡ºç°ï¼Œå³ä½¿åœ¨å¯¹å­—ç¬¦ä¸²è¿›è¡Œä¿®æ”¹æˆ–è¿æ¥æ—¶ä¹Ÿæ˜¯å¦‚æ­¤ï¼ˆæœ‰å…³å¦‚ä½•é¿å…è¿™ç§æƒ…å†µï¼Œè¯·å‚é˜…ä¸‹é¢çš„å†…å®¹ï¼‰ã€‚æœ‰å…³è§„èŒƒå½¢å¼ C å’Œè§„èŒƒç­‰ä»·çš„æ›´è¯¦ç»†ä¿¡æ¯ï¼Œè¯·å‚è§ Unicode åŸºé‡‘ä¼šå…³äº[è§„èŒƒåŒ–å’Œè§„èŒƒç­‰ä»·](https://unicode.org/reports/tr15/#Canon_Compat_Equivalence)çš„é¡µé¢ã€‚

Raku will turn both these inputs into one codepoint, as is specified for Normalization Form C (**NFC**). In most cases this is useful and means that two inputs that are equivalent are both treated the same. Unicode has a concept of canonical equivalence which allows us to determine the canonical form of a string, allowing us to properly compare strings and manipulate them, without having to worry about the text losing these properties. By default, any text you process or output from Raku will be in this â€œcanonicalâ€ form, even when making modifications or concatenations to the string (see below for how to avoid this). For more detailed information about Normalization Form C and canonical equivalence, see the Unicode Foundation's page on [Normalization and Canonical Equivalence](https://unicode.org/reports/tr15/#Canon_Compat_Equivalence).

æœ‰ä¸€ç§æƒ…å†µæ˜¯ï¼Œæˆ‘ä»¬ä¸é»˜è®¤è¿™æ ·åšï¼Œé‚£å°±æ˜¯æ–‡ä»¶çš„åç§°ã€‚è¿™æ˜¯å› ä¸ºæ–‡ä»¶çš„åç§°å¿…é¡»ä¸å†™å…¥ç£ç›˜çš„å­—èŠ‚å®Œå…¨ç›¸åŒã€‚

One case where we don't default to this, is for the names of files. This is because the names of files must be accessed exactly as the bytes are written on the disk.

ä¸ºäº†é¿å…è§„èŒƒåŒ–ï¼Œä½ å¯ä»¥ä½¿ç”¨åä¸º [UTF8-C8](https://docs.raku.org/language/unicode#UTF8-C8) çš„ç‰¹æ®Šç¼–ç æ ¼å¼ã€‚å°†è¿™ç§ç¼–ç ä¸ä»»ä½•æ–‡ä»¶å¥æŸ„ä¸€èµ·ä½¿ç”¨ï¼Œå°†å…è®¸ä½ è¯»å–ç£ç›˜ä¸Šçš„ç¡®åˆ‡å­—èŠ‚ï¼Œè€Œæ— éœ€è§„èŒƒåŒ–ã€‚å¦‚æœä½ ç”¨ UTF8 æ‰“å°å‡ºæ¥ï¼Œå®ƒä»¬åœ¨æ‰“å°å‡ºæ¥æ—¶å¯èƒ½çœ‹èµ·æ¥å¾ˆæ»‘ç¨½ã€‚å¦‚æœä½ å°†å®ƒæ‰“å°åˆ°è¾“å‡ºç¼–ç ä¸º UTF8-C8 çš„å¥æŸ„ä¸Šï¼Œé‚£ä¹ˆå®ƒå°†æŒ‰ç…§ä½ é€šå¸¸æ‰€æœŸæœ›çš„é‚£æ ·å‘ˆç°ï¼Œå¹¶ä¸”æ˜¯å­—èŠ‚ç²¾ç¡®å¤åˆ¶çš„å­—èŠ‚ã€‚å…³äº MoarVM çš„ [UTF8-C8](https://docs.raku.org/language/unicode#UTF8-C8) çš„æ›´å¤šæŠ€æœ¯ç»†èŠ‚å¦‚ä¸‹æ‰€è¿°ã€‚

To avoid normalization you can use a special encoding format called [UTF8-C8](https://docs.raku.org/language/unicode#UTF8-C8). Using this encoding with any filehandle will allow you to read the exact bytes as they are on disk, without normalization. They may look funny when printed out, if you print it out using a UTF8 handle. If you print it out to a handle where the output encoding is UTF8-C8, then it will render as you would normally expect, and be a byte for byte exact copy. More technical details on [UTF8-C8](https://docs.raku.org/language/unicode#UTF8-C8) on MoarVM are described below.

<a id="utf8-c8"></a>
## UTF8-C8

UTF-8 Clean-8 æ˜¯ä¸€ä¸ªç¼–ç å™¨/è§£ç å™¨ï¼Œä¸»è¦å¯¹ UTF-8 å·¥ä½œã€‚ä½†æ˜¯ï¼Œå½“é‡åˆ°ä¸€ä¸ªå­—èŠ‚åºåˆ—æ—¶ï¼Œå®ƒå°†ä½¿ç”¨ [NFG åˆæˆ](https://docs.raku.org/language/glossary#NFG)æ¥è·Ÿè¸ªæ‰€æ¶‰åŠçš„åŸå§‹å­—èŠ‚ã€‚è¿™æ„å‘³ç€ç¼–ç è¿”å›åˆ° UTF-8 Clean-8 å°†èƒ½å¤Ÿé‡æ–°åˆ›å»ºå­—èŠ‚ï¼Œå› ä¸ºä»–ä»¬åŸæ¥å­˜åœ¨ã€‚åˆæˆä½“åŒ…å« 4 ä¸ªç ç‚¹ï¼š

UTF-8 Clean-8 is an encoder/decoder that primarily works as the UTF-8 one. However, upon encountering a byte sequence that will either not decode as valid UTF-8, or that would not round-trip due to normalization, it will use [NFG synthetics](https://docs.raku.org/language/glossary#NFG) to keep track of the original bytes involved. This means that encoding back to UTF-8 Clean-8 will be able to recreate the bytes as they originally existed. The synthetics contain 4 codepoints:

- ç ç‚¹ 0x10FFFDï¼ˆå®ƒæ˜¯ä¸€ä¸ªä¸“ç”¨ç ç‚¹ï¼‰
- ç ç‚¹ 'x'
- ä¸å¯è§£ç å­—èŠ‚çš„ä¸Š 4 ä½ä½œä¸ºåå…­è¿›åˆ¶å­—ç¬¦ ï¼ˆ0..9A..Fï¼‰
- ä¸å¯è§£ç å­—èŠ‚çš„ä¸‹ 4 ä½ä½œä¸ºåå…­è¿›åˆ¶å­—ç¬¦ ï¼ˆ0..9A..Fï¼‰

- The codepoint 0x10FFFD (which is a private use codepoint)
- The codepoint 'x'
- The upper 4 bits of the non-decodable byte as a hex char (0..9A..F)
- The lower 4 bits as the non-decodable byte as a hex char (0..9A..F)

åœ¨æ­£å¸¸çš„ UTF-8 ç¼–ç ä¸‹ï¼Œè¿™æ„å‘³ç€æ— æ³•è¡¨ç¤ºçš„å­—ç¬¦å°†ä»¥ `?xFF` è¿™æ ·çš„å½¢å¼å‡ºç°ã€‚

Under normal UTF-8 encoding, this means the unrepresentable characters will come out as something like `?xFF`.

åœ¨ MoarVM æ¥æ”¶æ¥è‡ªç¯å¢ƒã€å‘½ä»¤è¡Œå‚æ•°å’Œæ–‡ä»¶ç³»ç»ŸæŸ¥è¯¢çš„å­—ç¬¦ä¸²çš„åœ°æ–¹ä½¿ç”¨ UTF-8 Clean-8ï¼Œä¾‹å¦‚åœ¨è§£ç ç¼“å†²åŒºæ—¶ï¼š

UTF-8 Clean-8 is used in places where MoarVM receives strings from the environment, command line arguments, and filesystem queries, for instance when decoding buffers:

```Raku
say Buf.new(ord('A'), 0xFE, ord('Z')).decode('utf8-c8');
#  OUTPUT: Â«Aô¿½xFEZâ¤Â»
```

ä½ å¯ä»¥çœ‹åˆ° UTF8-C8 ä½¿ç”¨çš„ä¸¤ä¸ªåˆå§‹ä»£ç ç‚¹æ˜¯å¦‚ä½•å‡ºç°åœ¨è¿™é‡Œçš„ï¼Œå°±åœ¨ â€œFEâ€ ä¹‹å‰ã€‚ä½ å¯ä»¥ä½¿ç”¨è¿™ç§ç±»å‹çš„ç¼–ç æ¥è¯»å–å…·æœ‰æœªçŸ¥ç¼–ç çš„æ–‡ä»¶ï¼š

You can see how the two initial codepoints used by UTF8-C8 show up here, right before the "FE". You can use this type of encoding to read files with unknown encoding:

```Raku
my $test-file = "/tmp/test";
given open($test-file, :w, :bin) {
  .write: Buf.new(ord('A'), 0xFA, ord('B'), 0xFB, 0xFC, ord('C'), 0xFD);
  .close;
}
 
say slurp($test-file, enc => 'utf8-c8');
# OUTPUT: Â«(65 250 66 251 252 67 253)Â»
```

ä½¿ç”¨è¿™ç§ç±»å‹çš„ç¼–ç è¯»å–å¹¶å°†å®ƒä»¬ç¼–ç å› UTF8-C8 å°†è¿”å›åŸå§‹å­—èŠ‚ï¼›è¿™åœ¨é»˜è®¤çš„ UTF-8 ç¼–ç ä¸­æ˜¯ä¸å¯èƒ½çš„ã€‚

Reading with this type of encoding and encoding them back to UTF8-C8 will give you back the original bytes; this would not have been possible with the default UTF-8 encoding.

è¯·æ³¨æ„ï¼Œåˆ°ç›®å‰ä¸ºæ­¢ï¼Œåœ¨ Rakudo çš„ JVM å®ç°ä¸­ä¸æ”¯æŒè¿™ç§ç¼–ç ã€‚

Please note that this encoding so far is not supported in the JVM implementation of Rakudo.

<a id="è¾“å…¥-unicode-ç ç‚¹å’Œç ç‚¹åºåˆ—--entering-unicode-codepoints-and-codepoint-sequences"></a>
# è¾“å…¥ Unicode ç ç‚¹å’Œç ç‚¹åºåˆ— / Entering unicode codepoints and codepoint sequences

ä½ å¯ä»¥æŒ‰æ•°å­—(åè¿›åˆ¶å’Œåå…­è¿›åˆ¶)è¾“å…¥ Unicode ç ç‚¹ã€‚ä¾‹å¦‚ï¼Œåä¸º "latin capital letter ae with macron" çš„å­—ç¬¦æœ‰åè¿›åˆ¶ç ç‚¹ 482 å’Œåå…­è¿›åˆ¶ç ç‚¹ 0x1E2ï¼š

You can enter Unicode codepoints by number (decimal as well as hexadecimal). For example, the character named "latin capital letter ae with macron" has decimal codepoint 482 and hexadecimal codepoint 0x1E2:

```Raku
say "\c[482]"; # OUTPUT: Â«Ç¢â¤Â» 
say "\x1E2";   # OUTPUT: Â«Ç¢â¤Â»
```

ä½ è¿˜å¯ä»¥æŒ‰åç§°è®¿é—® Unicode ç ç‚¹ï¼šRaku æ”¯æŒæ‰€æœ‰ Unicode åç§°ã€‚

You can also access Unicode codepoints by name: Raku supports all Unicode names.

```Raku
say "\c[PENGUIN]"; # OUTPUT: Â«ğŸ§â¤Â» 
say "\c[BELL]";    # OUTPUT: Â«ğŸ””â¤Â» (U+1F514 BELL)
```

æ‰€æœ‰ Unicode ä»£ç ç‚¹åç§°/å‘½åçš„ seq/moji åºåˆ—ç°åœ¨éƒ½æ˜¯ä¸åŒºåˆ†å¤§å°å†™çš„ï¼š[ä» Rakudo 2017.02 å¼€å§‹]

All Unicode codepoint names/named seq/emoji sequences are now case-insensitive: [Starting in Rakudo 2017.02]

```Raku
say "\c[latin capital letter ae with macron]"; # OUTPUT: Â«Ç¢â¤Â» 
say "\c[latin capital letter E]";              # OUTPUT: Â«Eâ¤Â» (U+0045)
```

å¯ä»¥é€šè¿‡ä½¿ç”¨å¸¦æœ‰ `\c[]` çš„é€—å·åˆ†éš”åˆ—è¡¨æ¥æŒ‡å®šå¤šä¸ªå­—ç¬¦ã€‚è¿˜å¯ä»¥ç»„åˆæ•°å­—æ ·å¼å’Œå‘½åæ ·å¼ï¼š

You can specify multiple characters by using a comma separated list with `\c[]`. You can combine numeric and named styles as well:

```Raku
say "\c[482,PENGUIN]"; # OUTPUT: Â«Ç¢ğŸ§â¤Â»
```

é™¤äº†åœ¨å­—ç¬¦ä¸²æ’å€¼ä¸­ä½¿ç”¨ `\c[]` ä¹‹å¤–ï¼Œè¿˜å¯ä»¥ä½¿ç”¨ [uniparse](https://docs.raku.org/routine/uniparse)ï¼š

In addition to using `\c[]` inside interpolated strings, you can also use the [uniparse](https://docs.raku.org/routine/uniparse):

```Raku
say "DIGIT ONE".uniparse;  # OUTPUT: Â«1â¤Â» 
say uniparse("DIGIT ONE"); # OUTPUT: Â«1â¤Â»
```

<a id="åç§°åˆ«å--name-aliases"></a>
## åç§°åˆ«å / Name aliases

åç§°åˆ«åä¸»è¦ç”¨äºæ²¡æœ‰æ­£å¼åç§°çš„ç ç‚¹ã€ç¼©å†™æˆ–æ›´æ­£ï¼ˆUnicode åç§°æ°¸ä¸æ›´æ”¹ï¼‰ã€‚ä»–ä»¬çš„å®Œæ•´åå•è§[æ­¤å¤„](https://www.unicode.org/Public/UCD/latest/ucd/NameAliases.txt)ã€‚

Name Aliases are used mainly for codepoints without an official name, for abbreviations, or for corrections (Unicode names never change). For full list of them see [here](https://www.unicode.org/Public/UCD/latest/ucd/NameAliases.txt).

æ²¡æœ‰ä»»ä½•å®˜æ–¹åç§°çš„æ§åˆ¶ä»£ç ï¼š

Control codes without any official name:

```Raku
say "\c[ALERT]";     # Not visible (U+0007 control code (also accessible as \a)) 
say "\c[LINE FEED]"; # Not visible (U+000A same as "\n")
```

æ›´æ­£ï¼š

Corrections:

```Raku
say "\c[LATIN CAPITAL LETTER GHA]"; # OUTPUT: Â«Æ¢â¤Â» 
say "Æ¢".uniname; # OUTPUT: Â«LATIN CAPITAL LETTER OIâ¤Â» 
# This one is a spelling mistake that was corrected in a Name Alias: 
say "\c[PRESENTATION FORM FOR VERTICAL RIGHT WHITE LENTICULAR BRACKET]".uniname;
# OUTPUT: Â«PRESENTATION FORM FOR VERTICAL RIGHT WHITE LENTICULAR BRAKCETâ¤Â»
```

ç¼©å†™ï¼š

Abbreviations:

```Raku
say "\c[ZWJ]".uniname;  # OUTPUT: Â«ZERO WIDTH JOINERâ¤Â» 
say "\c[NBSP]".uniname; # OUTPUT: Â«NO-BREAK SPACEâ¤Â»
```

<a id="å‘½ååºåˆ—--named-sequences"></a>
## å‘½ååºåˆ— / Named sequences

ä½ è¿˜å¯ä»¥ä½¿ç”¨ä»»ä½•[å‘½ååºåˆ—](https://www.unicode.org/Public/UCD/latest/ucd/NamedSequences.txt)ï¼Œè¿™äº›ä¸æ˜¯å•ä¸ªä»£ç ç‚¹ï¼Œè€Œæ˜¯å®ƒä»¬çš„åºåˆ—ã€‚[ä» 2017.02 Rakudo å¼€å§‹]

You can also use any of the [Named Sequences](https://www.unicode.org/Public/UCD/latest/ucd/NamedSequences.txt), these are not single codepoints, but sequences of them. [Starting in Rakudo 2017.02]

```Raku
say "\c[LATIN CAPITAL LETTER E WITH VERTICAL LINE BELOW AND ACUTE]";      # OUTPUT: Â«Ã‰Ì©â¤Â» 
say "\c[LATIN CAPITAL LETTER E WITH VERTICAL LINE BELOW AND ACUTE]".ords; # OUTPUT: Â«(201 809)â¤Â»
```

<a id="è¡¨æƒ…åºåˆ—--emoji-sequences"></a>
### è¡¨æƒ…åºåˆ— / Emoji sequences

Raku æ”¯æŒè¡¨æƒ…åºåˆ—ã€‚æ‰€æœ‰è¿™äº›æ–‡ä»¶è§ï¼š[Emoji ZWJ åºåˆ—](https://www.unicode.org/Public/emoji/4.0/emoji-zwj-sequences.txt) å’Œ [Emoji åºåˆ—](https://www.unicode.org/Public/emoji/4.0/emoji-sequences.txt)ã€‚è¯·æ³¨æ„ï¼Œä»»ä½•å¸¦æœ‰é€—å·çš„åç§°éƒ½åº”è¯¥åˆ é™¤å®ƒä»¬çš„é€—å·ï¼Œå› ä¸º Raku ä½¿ç”¨é€—å·æ¥åˆ†éš”ç›¸åŒ `\c` åºåˆ—ä¸­çš„ä¸åŒä»£ç ç‚¹/åºåˆ—ã€‚

Raku supports Emoji sequences. For all of them see: [Emoji ZWJ Sequences](https://www.unicode.org/Public/emoji/4.0/emoji-zwj-sequences.txt) and [Emoji Sequences](https://www.unicode.org/Public/emoji/4.0/emoji-sequences.txt). Note that any names with commas should have their commas removed, since Raku uses commas to separate different codepoints/sequences inside the same `\c` sequence.

```Raku
say "\c[woman gesturing OK]";         # OUTPUT: Â«ğŸ™†â€â™€ï¸â¤Â» 
say "\c[family: man woman girl boy]"; # OUTPUT: Â«ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦â¤Â»
```
